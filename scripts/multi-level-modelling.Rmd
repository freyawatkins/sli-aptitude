 ---
title: "multi-level-modelling"
author: "Freya Watkins"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 5
    number_sections: false
    theme: flatly
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load tidyverse:
```{r}
library(tidyverse)
```

# Multilevel Modelling in R

## Tutorial Video 1: Unconditional *Means* Model (Null Model)
[video](https://www.youtube.com/watch?v=cr9RpSgRYVw)

The unconditional means model is the null model, which includes no predictors (independent variables) or measures of time. Running the unconditional means model is to test the significance of the grand mean and intercept of your model. Building the unconditional means model is the first step in analyzing longitudinal data using multilevel modeling. 

Research Q: Can we reject the NULL hyp. that the grand mean for the intercept is equal to zero?

### STEP 1: Read in dataset 
Make sure file is a .csv and not a .xls worksheet
Make sure data is in long format, i.e. multiple rows per ppt per session.
```{r}
apt <- read.csv("data/2021-09-30_SLI_aptitude_data.csv")
```

!!! BEGIN TIMEPOINTS WITH 0, not 1 !!! else you would be skewing your results.

```{r}
names(apt)
apt <- dplyr::rename(apt, session = "Ã¯..session") # fix

# shift so that 1st session=0
apt$session <- apt$session-1
apt$session # check

# replace HW or WV code with nothing
apt$ppt <- gsub("HW|WV", "", apt$ppt) 
apt$ppt <- as.numeric(apt$ppt)

# multiply nback_lett by 100
apt$nback_lett <- apt$nback_lett * 100
```

### STEP 2: Open {nlme} package
nlme: linear and nonlinear mixed effects models
```{r}
library(nlme)
```
There are other packages available incl. {lme4}

### STEP 3: Examine head of data
```{r}
head(apt)
```

### STEP 4: Run unconditional means model (UMM) w/ summary
We are using ppt as the nested variable/random effect, i.e. ppts are nested within themselves compared at diff time points. Some might think to use e.g. group or uni as the random effect since it is another level of clustering, but this is a  longitudinal design, so must be nested based on individuals. The first ~1 refers to no slope/random effects at this point

```{r}
# select relevant cols, remove NA rows
nback1 <- apt %>% select(session, group, ppt, nback_lett) %>% filter(nback_lett != "NA")
```

```{r}
mod1 <- lme(nback_lett~1, random=~1|ppt, data=nback1, method="ML")

summary(mod1)
```

Looking at the ouput: the logLik value is 95.4666. Ideally this gets smaller as the model builds up as the model improves in fit. Then we can test if the decrease is different from original model.
Random effects StdDev Intercept & Residuals help us calculate the intra-class correlation coefficient: how much clustering could exist within data.
Fixed effects: p value is 0 (significant). We have an intercept (Value), which is 0.7165711, significantly different from 0: can reject the null. 
Number of Groups: 33 is the no of participants. Number of Observations: 56 is the total times task was completed 

IMPORTANT NOTES ABOUT THIS MODEL
- No predictors in the model (no independent variables)
- This is the null model (beginning of intercept only)
- Time is not being measured within this model
- Measuring the grand mean here

### STEP 5: Run intervals for the unconditional means model

```{r}
intervals(mod1)
```
Fixed effects est. is the same as Value from before (0.7165711)
We also get lower and upper estimates. We know the confidence interval is significant from the p-value being 0 above.
Under random effects, it also has CIs. These suggest that individuals do vary. Important to make sure that lower value only is not below 0. Otherwise suggests the CI is not significant. So we can say that there is individual variability to be measured within our model

### STEP 6: Calculate intra-class correlation coefficient for the UMM
For participants:
```{r}
# have to manually calculate
(0.02088573^2) / ((0.02088573^2) + (0.03927826^2))
```

We get 0.2204218. So 22% variability exists. So a bit of clustering is taking place. We need to flush it out by selecting a proper slope and then by using our predictors to see how much of that variability we can account for. If this value were <.05, would suggest no clustering is happening and MLM would be less appropriate.

So here we're not testing any hypothesis at this point. Just looking to see how much the interval differs from 0. We can use the I-CCC to see if we should proceed with multi-level modelling. 

## Tutorial Video 2: Unconditional *Growth* Model (Setting up the slope)
[video](https://www.youtube.com/watch?v=XvO9p5LVjrU)

The unconditional growth model includes a measure of time across a slope (either being a fixed or a random slope). By running the unconditional growth model, we can test the appropriateness of the slope, and whether the slope for the model should be fixed or random. The unconditional growth model can also be compared with the unconditional means model for "model fit". The unconditional growth model does not include any other predictors (independent variables). All other predictors will be included in the condition growth model, which is the full model.

In the 1st section we saw the UMM follows the assumption that everyone is following a similar pattern. But random slopes allow for individual variability e.g. over time.
Now we're going to test the slope to see if it will be fixed or random. 

Going back to the RQ, we only looked at the dependent variable. Now we can include a time variable, i.e. Session. This will help us set up the slope. So after running both a model with fixed slopes and one with random slopes, we can compare to see which one significantly differs from the UMM.

### STEPS 1-3: Same as Tutorial one
Load and inspect data, load {nlme} package

### STEP 4: Begin plotting the data to see individual slopes
We want to determine whether Session should have a fixed or random slope
```{r}
library(lattice)

xyplot(nback_lett ~ session | ppt, 
       data = nback1, type = c("p", "r"))
```
So we can see some improve, some get worse over time. Looks like we clearly want random slopes, but let's try both anyway

### STEP 5: Run the unconditional growth models
#### a) Unconditional growth model (mod2) - Session as a fixed slope
```{r}
mod2 <- lme(nback_lett ~ session, random=~1|ppt,
            data = nback1, method = "ML")
summary(mod2)
```
Strangely running within a chunk does not give the logLik - whereas in the console it does. Our logLik is still quite large, almost identical, 97.15697.
Our Random effects Intercept & Residual values can help us to calculate our I-CCC. If the fixed slope is accounting for a lot of the variance, our I-CCC should decrease over time. We'll compare them later.
Fixed effects: nback_lett ~ session. looking at p-value, it's not significant (0.0802). So creating a fixed slope for this sample is not actually capturing the fit of the model. 

Now let's run the confidence intervals
```{r}
intervals(mod2)
```
We can see they're not significant because the fixed effects lower CI is negative whereas the others are positive =  not significant. So session as a fixed slope is not significant.
Interestingly when we look at the random effects, these are still significant. All values are positive. So we can see right away that the random effects are significant. This is promising, which suggests we can structure the model in a better way. So now let's do it with session as a random slope

#### b) Unconditional growth model (mod3) - Session as a random slope
This model accounts for individual variability
```{r}
mod3 <- lme(nback_lett~session,random=~session|ppt,data=nback1,method="ML")
summary(mod3)
```
So, the logLik should be reduced if the model has improved. It seems to be identical to mod2 though (97.15697) - not sure why.
Under Fixed effects, session is still not significant because it is not a fixed effect/fixed slope. But including it as a random slope we know it is significant. Let's look at the intervals:
```{r}
# intervals(mod3)
```
This gives an error: "cannot get confidence intervals on var-cov components". Not sure why

In the tutorial dataset, the model with session as a random slope is clearly preferred, as the two groups sharply contrast in their performance based on training peformance overtime. Maybe there isn't enough variation among my participants in change over time, so possibly a fixed slope for time is fine after all?

We can see if the models differ by running anovas (mod 1 vs mod 2; mod 1 vs mod 3). 

### STEP 6: Run deviance statistics.
#### a) First, rerun the unconditional means model (mod1) from before:
```{r}
mod1 <- lme(nback_lett~1, random=~1|ppt, data=nback1, method="ML")
summary(mod1)
intervals(mod1)
```

#### b) Compare UMM to UGM with a fixed slope (mod 2)
```{r}
(results <- anova(mod1,mod2))
results$`p-value`
```
It's not significant (just!) p = .066
The log-Lik values are fairly similar
So possibly having a fixed slope has marginally improved fit of data

#### c) Compare UMM to UGM with a random slope (mod 3)
```{r}
(results <- anova(mod1,mod3))
results$`p-value`
```
Also not significant p = .336
In the tutorial, the p-value was very significant, suggesting a random slope had really improved the model fit to the data.

### STEP 7: Calculate intra-class correlation coefficient (ICC) for each model

ICC for UMM (mod1):
```{r}
variance.partitions <- VarCorr(mod1)
between.v <- as.numeric(variance.partitions[1,1])
within.v <- as.numeric(variance.partitions[2,1])
ICC.estimate  <- between.v/ (between.v + within.v)
print(ICC.estimate) 
```
Some clustering taking place in the data (0.22) suggesting a multi level modelling is appropriate

ICC for UMM (mod2):
```{r}
variance.partitions <- VarCorr(mod2)
between.v <- as.numeric(variance.partitions[1,1])
within.v <- as.numeric(variance.partitions[2,1])
ICC.estimate  <- between.v/ (between.v + within.v)
print(ICC.estimate) 
```
Similar ICC with a fixed slope (0.23)

ICC for UMM (mod3)
```{r}
variance.partitions <- VarCorr(mod3)
between.v <- as.numeric(variance.partitions[1,1])
within.v <- as.numeric(variance.partitions[2,1])
ICC.estimate  <- between.v/ (between.v + within.v)
print(ICC.estimate) 
```
Once we add a random slope, the clustering has gone up even higher. But 1 is too high, surely! We can't be accounting for 100% of the variability in the clustering. This may be why the intervals are not working

## Tutorial Video 3: *Conditional Growth* Model (Full Model)
[video](https://www.youtube.com/watch?v=wVI5-iqOpLA)

The conditional growth model, which is full model, is built upon the unconditional growth model, which establishes a measure of time across a slope (either being a fixed or a random slope). The conditional growth model includes all predictors (independent variables) of the dependent variable or outcome. If you have specific hypotheses or research questions about your longitudinal data, this would be the stage at which you could begin to include your predictors within the model. By running the conditional growth model, we can test our research questions and examine interactions between predictors on the dependent variable.  We can also compare the conditional growth model (full model) to the unconditional growth model (with slope) for "model fit" and examine the predictive power of our independent variables.

So we now need to add the predictors/independent variables to the study, i.e. Job_Site; Satisfaction_with_Trainer; Job_Satisfaction.
Or for my data, 'university' or 'group' would be a good proxy for Job_Site

We'll compare this full model with all predictors to the UGM with a random slope (mod3), but there is no need to compare to the UGM a fixed slope (mod2) because this has already been ruled out as not sig different from the UMM/not an appropriate fit for the data.

### STEPS 1-2: Same as Tutorial one
Load and inspect data, load {nlme} package

### STEP 3: Run conditional growth model (full model)
Ideally, we should also recode Group as 1 and 2 first
```{r}
nback1$group <- plyr::revalue(nback1$group, c("pilot" = 1, 
                                            "grant" = 2))
nback1$group <- as.numeric(nback1$group)
```

```{r}
mod4 <- lme(nback_lett ~ session + group + # adding group as predictor
            session*group, #using * instead of + is for interaction predictions
            random = ~session|ppt,
            data = nback1, 
            method = "ML")

summary(mod4)
#intervals(mod4)
```
### STEP 4: Examine interaction plots
Group and Session
```{r}
interaction.plot(nback1$session, nback1$group, nback1$nback_lett)
```
Or other plotting techniques:
```{r}
xyplot(nback_lett ~ session | ppt, data = nback1, 
       groups = group, type = c("p", "r"))
```
Group and Session
```{r}
xyplot(nback_lett ~ session | group, data = nback1, 
       prepanel = function(x, y) prepanel.loess(x, y, family = "gaussian"),
       xlab = "Session", ylab = "N-Back Letter Score",
       panel = function(x, y) {panel.xyplot(x, y)
         panel.loess(x, y, family = "gaussian") }, as.table = TRUE)
# not sure what is going on here on the right panel
```

### STEP 5: Run deviance statistics
First, rerun the unconditional growth model (mod3) with random slope from before
```{r}
mod3 <- lme(nback_lett~session,random=~session|ppt,data=nback1,method="ML")
summary(mod3)
#intervals(mod3)
```

Compare UGM (mod3) w/ random slope to full CGM (mod4)
```{r}
(results <- anova(mod3, mod4))
results$`p-value`
```
not significant, so group is not predicting nback_lett results

### STEP 6: Calculate intra-class correlation coefficient (ICC) for full model
```{r}
variance.partitions <- VarCorr(mod4)
between.v <- as.numeric(variance.partitions[1,1])
within.v <- as.numeric(variance.partitions[2,1])
ICC.estimate  <- between.v/ (between.v + within.v)
print(ICC.estimate) 
```
### STEP 7: Calculate the proportion reduction between the UGM with a random slope (mod3) and the CGM with all predictors (mod4)
For the full model, this is more important to calculate than the ICC

Level 1 is comparing session (repeated measures) to nback_lett, this is at the repeated measures model
```{r}
VarCorr(mod3)[1,1]

VarCorr(mod4)[1,1]
```
This provides the unexplained variance captured in the full model
```{r}
(as.numeric(VarCorr(mod3)[1,1])-as.numeric(VarCorr(mod4)[1,1])) / as.numeric(VarCorr(mod3)[1,1])
```
So only 3% of that variance is being captured by the full model

Level 2 is comparing session plus all predictors to nback_lett, at the individual level
```{r}
VarCorr(mod3)[2,1]

VarCorr(mod4)[2,1]
```
Now with the additional group predictor in place, is there more variance explained?
```{r}
(as.numeric(VarCorr(mod3)[2,1])-as.numeric(VarCorr(mod4)[2,1])) / as.numeric(VarCorr(mod3)[2,1])
```
No, is the answer. Still around 3%.

So that's pretty much everything for running a two-level longitudinal multi-level model in R!